{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Written by Dr Daniel Buscombe, Northern Arizona University\n",
    "\n",
    "> Part of a series of notebooks for image recognition and classification using deep convolutional neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates some strategies for image recognition using common machine learning techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import s3fs\n",
    "fs = s3fs.S3FileSystem(anon=True)\n",
    "\n",
    "root = 'esipfed/cdi-workshop'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://www.bogotobogo.com/python/scikit-learn/images/features/FeatureExtraction.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll work with a dataset consisting of images of sandbars in Grand Canyon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [f for f in fs.ls(root+'/semseg_data/sandbars') if f.endswith('.JPG')]\n",
    "# all files in <directory> which end in '.jpg' store in frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('We have %i images' % len(frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import some image reading/resizing functions\n",
    "from scipy.misc import imresize\n",
    "from imageio import imread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the images into an array, downsizing by an eigth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [] # create an empty list in the memory\n",
    "for file in frames: # for all items in the list frames\n",
    "    with fs.open(file, 'rb') as f: # use the .open() method (readbyte=rb) on files and store as 'f'\n",
    "        examples.append(imresize(imread(f), .125)) # resize files stored in 'f', and append them into the empty list called examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the size of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx, ny, nz = np.shape(examples[0]) # find the size of each dimension of the first image stored in the list examples[]\n",
    "nx, ny, nz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a vector of labels for each image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [f.split('/')[-1].split('_')[0] for f in frames] # split the filename at the forward slashes, extract the last item (filename)\n",
    "# split the filename at the underscores and take the first part of the string (sitename), store site names for all 'f' in frames[] in a list names[]\n",
    "names[0]  # return the value for the first item in the list names[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an indexing vector and plot some example images with their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=np.arange(len(frames)) # create a numpy array with the number of values = the length of the list frames[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(8, 5)\n",
    "fig.set_figheight(15)\n",
    "fig.set_figwidth(15)\n",
    "for i, axi in enumerate(ax.flat):\n",
    "    axi.imshow(examples[i])\n",
    "    axi.set(xticks=[], yticks=[],\n",
    "            ylabel=names[target[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually we need to flatten the images into 1d vectors so let's create that data set again\n",
    "\n",
    "We need to flatten the images from 3D to 1D so we can use a random forest classifier. Essentially, just the pixel values, not their relative spatial position, are important for this algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read in again, this time flattening\n",
    "examples = []\n",
    "for file in frames:\n",
    "    with fs.open(file, 'rb') as f:\n",
    "        examples.append(imresize(imread(f), (nx,ny,nz)).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to classify each image into classes which are 'sites'. We'll create a numeric code for each sandbar site\n",
    "\n",
    "What the code below does is assign a numeric class to every image. For example, the first 6 images are from site 0, the next 4 from site 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {ni: indi for indi, ni in enumerate(set(names))}\n",
    "target = sorted([d[ni] for ni in names])\n",
    "target[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll use the utility function ```train_test_split``` provided by scikit-learn, to create a random split of test and train images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(examples, target,\n",
    "                                                random_state=42, test_size=0.3)\n",
    "## this function splits our data into a training set and a testing set\n",
    "# Xtrain is a subset of our data that we will train the model with\n",
    "# Xtest is a subet of our data that we will validate with\n",
    "# ytrain is the labels for the training dataset\n",
    "# ytest is the labels of the validation dataset\n",
    "# random_state = 42 sets a seed for the random number generator ensuring that you get the same random number as me\n",
    "# test_size = 0.3 specifies that 30% of the dataset will be used for validation or testing while 70% is used for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 35 training images, each consisting of 570312 features (pixels). We have 16 test images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(Xtrain))\n",
    "print(len(Xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_names = np.unique(names)\n",
    "print(uniq_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now we have a testing and training data set and labels. We're ready to start classifying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forests are an example of an ensemble learner built on decision trees. Decision trees are extremely intuitive ways to classify or label objects: you simply ask a series of questions designed to zero-in on the classification. \n",
    "\n",
    "\n",
    "#### Decision tree\n",
    "\n",
    "In a well-constructed tree, each question will cut the number of options by approximately half, very quickly narrowing the options even among a large number of classes. The trick, of course, comes in deciding which questions to ask at each step. In machine learning implementations of decision trees, the questions generally take the form of axis-aligned splits in the data: that is, each node in the tree splits the data into two groups using a cutoff value within one of the features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://jakevdp.github.io/PythonDataScienceHandbook/figures/05.08-decision-tree.png)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier().fit(np.squeeze(Xtrain), ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple decision tree built on this data will iteratively split the data along one or the other axis according to some quantitative criterion, and at each level assign the label of the new region according to a majority vote of points within it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a quick utility function to help us visualize the output of the classifier\n",
    "\n",
    "This function will take the training data (X: sandbar images) and the associated labels (y: sandbar site labels), and show the 'decision space' as shaded colored regions. Each color represents a different class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_classifier(model, X, y, ax=None, cmap='rainbow'):\n",
    "    ax = ax or plt.gca()\n",
    "    \n",
    "    # Plot the training points\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, s=30, cmap=cmap,\n",
    "               clim=(y.min(), y.max()), zorder=3)\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "    \n",
    "    # fit the estimator\n",
    "    model.fit(X, y)\n",
    "    xx, yy = np.meshgrid(np.linspace(*xlim, num=200), # np.linspace() creates linearly spaced sequence of numbers\n",
    "                         np.linspace(*ylim, num=200))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)## .ravel() flattens arrays into one dimension\n",
    "\n",
    "    # Create a color plot with the results\n",
    "    n_classes = len(np.unique(y))\n",
    "    contours = ax.contourf(xx, yy, Z, alpha=0.3,\n",
    "                           levels=np.arange(n_classes + 1) - 0.5, # np.arange(n) creates a sequence of number from 0 to n\n",
    "                                                                   # then 0.5 is subtracted from every item in the sequence and sored in 'levels'\n",
    "                           cmap=cmap, clim=(y.min(), y.max()),\n",
    "                           zorder=1)\n",
    "\n",
    "    ax.set(xlim=xlim, ylim=ylim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can examine what the decision tree classification looks like. We'll just use the first 2 features (columns) in X, which are just the first 2 pixels across all 35 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xim = np.squeeze(Xtrain)[:,:2] ## 'squeeze' removes singleton dimensions, ':2' means 'just the first 2 columns'\n",
    "yim = np.asarray(ytrain)\n",
    "print(np.shape(Xim))\n",
    "print(np.shape(yim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot below shows different sites as colored dots (there are 35 dots corresponding to 35 images), and the colored regions show the portion of that parameter space assigned to each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_classifier(DecisionTreeClassifier(), Xim, yim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In reality, this is done in 570312 dimensions at once, but I can only view 2 or 3 at a time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, our features are highly correlated and their choice is arbitrary, so we could use principal components (see lesson 2) to remove the redundancy in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca  =  PCA(n_components =2)\n",
    "## fit to data\n",
    "pca.fit(Xtrain)\n",
    "## apply the transformation\n",
    "images_pca = pca.transform(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(images_pca)\n",
    "visualize_classifier(DecisionTreeClassifier(), images_pca, yim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to fit the decision tree classifier to the entire (un-PCA'd) dataset (not just the first 2 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier().fit(np.squeeze(Xtrain), ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## mean accuracy on the given test data and labels.\n",
    "tree.score(np.squeeze(Xtest), ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fairly low. What if we use principal components to transform the imagery into features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca  =  PCA(n_components =30)\n",
    "## fit to data\n",
    "pca.fit(Xtrain)\n",
    "## apply the transformation\n",
    "images_pca = pca.transform(Xtrain)\n",
    "\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About 10 components explains ~90% of the variance. Let's use those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca  =  PCA(n_components =10).fit(Xtrain)\n",
    "## apply the transformation\n",
    "images_pca = pca.transform(Xtrain)\n",
    "\n",
    "# apply model to test data\n",
    "tree = DecisionTreeClassifier().fit(images_pca, ytrain)\n",
    "tree.score(pca.transform(Xtest), ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better accuracy. How does the Random Forest compare?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest\n",
    "\n",
    "A random forest is a collection of decision trees that have been trained on randomly selected subsets of data.\n",
    "\n",
    "They make predictions by returning the mean of the trees' predictions\n",
    "\n",
    "They are less prone to overfitting because no single tree can learn from all the instances and explanatory variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=1000)\n",
    "model.fit(np.squeeze(images_pca), ytrain)\n",
    "ypred = model.predict(pca.transform(Xtest))           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(pca.transform(Xtest), ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better still. Why?\n",
    "\n",
    "Decision trees suffer from over-fitting: it is very easy to go too deep in the tree, and thus to fit details of the particular data rather than the overall properties of the distributions they are drawn from.\n",
    "\n",
    "The random forest – an ensemble of randomized decision trees - is a powerful method with several advantages:\n",
    "\n",
    "* The multiple trees allow for a probabilistic classification: a majority vote among estimators gives an estimate of the probability (accessed in Scikit-Learn with the predict_proba() method).\n",
    "\n",
    "* The nonparametric model is extremely flexible, and can thus perform well on tasks that are under-fit by other estimators.\n",
    "\n",
    "Before we continue, let's dive into evaluation criteria a little deeper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy statistics\n",
    "\n",
    "Precision-Recall is a useful measure of success of prediction when the classes are very imbalanced (unequal number of examples per class) \n",
    "\n",
    "#### Precision\n",
    "\n",
    "is a measure of the fraction of the data that is correctly classified (positively). \n",
    "\n",
    "For example, the fraction of water pixels that are actually water\n",
    "\n",
    "#### Recall (Sensitivity)\n",
    "\n",
    "is a measure of the fraction of the data classes that are correctly identified. For example, the fraction of true water pixels that were detected\n",
    "\n",
    "They are both useful because the classifier with impressive accuracy could actually fail to detect most water pixels\n",
    "\n",
    "#### The F1 score \n",
    "\n",
    "is an equal weighting of the recall and precision and quantiﬁes how well the model performs in general.\n",
    "\n",
    "It penalizes classifiers with imbalanced precision and recall scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FP/FN/TP/TN\n",
    "A system with high recall but low precision returns many correct results, but most of its predicted labels are incorrect when compared to the training labels. \n",
    "\n",
    "A system with high precision but low recall is just the opposite, returning very few correct results, but most of its predicted labels are correct when compared to the training labels. \n",
    "\n",
    "True positives are image regions/pixels correctly classiﬁed as belonging to a certain class by the model, while true negatives are correctly classiﬁed as not belonging to a certain class. \n",
    "\n",
    "False negatives (Type 2 error) are regions/pixels incorrectly classiﬁed as not belonging to a certain class, and false positives (Type 1 error) are those regions/pixels incorrectly classiﬁed as belonging to a certain class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://nlpforhackers.io/wp-content/uploads/2017/01/Precision-Recall.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision\n",
    "\n",
    "Precision ($P$) is defined as the number of true positives ($T_p$) over the number of true positives plus the number of false positives ($F_p$).\n",
    "\n",
    "$P = \\frac{T_p}{T_p+F_p}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recall\n",
    "\n",
    "Recall ($R$) is defined as the number of true positives ($T_p$) over the number of true positives plus the number of false negatives ($F_n$).\n",
    "\n",
    "$R = \\frac{T_p}{T_p + F_n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 score\n",
    "\n",
    "These quantities are also related to the ($F_1$) score, which is defined as the harmonic mean of precision and recall.\n",
    "\n",
    "$F1 = 2\\frac{P \\times R}{P+R}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(ypred, ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix\n",
    "\n",
    "A “confusion matrix”, which is the matrix of normalized correspondences between true and estimated labels, is a convenient way to visualize model skill. \n",
    "\n",
    "A perfect correspondence between true and estimated labels is scored 1.0 along the diagonal elements of the matrix. \n",
    "\n",
    "Misclassifications are readily identified as off-diagonal elements. Systematic misclassifications are recognized as off-diagonal elements with large magnitudes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize: #normalization means scaling all row elements so each row sums to 1\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar(shrink=0.75)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45) ## we rotate the tick labels so we can see them better\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd' ## this is a formating string that plots\n",
    "    ## floating point (2 decimal places) if normalized values, or integers otherwise\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.axis('tight')\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "mat = confusion_matrix(ytest, ypred)\n",
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(mat, classes=uniq_names,\n",
    "                      title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(mat, classes=uniq_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hold back some subset of the data from the training of the model, and then use this holdout set to check the model performance\n",
    "\n",
    "A sequence of fits where each subset of the data is used both as a training set and as a validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we do two validation trials, alternately using each subset of the data as a holdout set. Using the split data from before, we could implement it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_model = model.fit(pca.transform(Xtrain), ytrain).predict(pca.transform(Xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_model = model.fit(pca.transform(Xtest), ytest).predict(pca.transform(Xtrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(ytrain, y1_model), metrics.accuracy_score(ytest, y2_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What comes out are two accuracy scores, which we could combine (by, say, taking the mean) to get a better measure of the global model performance. This particular form of cross-validation is a two-fold cross-validation—that is, one in which we have split the data into two sets and used each in turn as a validation set.\n",
    "\n",
    "We could expand on this idea to use even more trials, and more folds in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we split the data into five groups, and use each of them in turn to evaluate the model fit on the other 4/5 of the data. This would be rather tedious to do by hand, and so we can use Scikit-Learn's cross_val_score convenience routine to do it succinctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "# we are stacking the training and testing data so the training 2D arrays sits on top of the testing 2D array (vertical stack)\n",
    "X = np.vstack((pca.transform(Xtrain), pca.transform(Xtest)))\n",
    "print(np.shape(X))\n",
    "# we are stacking the associated 'y' (label) vectors. Because these are both 1D, we use the 'hstack' command\n",
    "y = np.hstack((ytrain, ytest))\n",
    "print(np.shape(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### AN EXAMPLE OF np.hstack and np.vstack\n",
    "##>>> np.vstack(([1,2,3],[4,5,6]))\n",
    "##array([[1, 2, 3],\n",
    "##       [4, 5, 6]])\n",
    "##>>> np.column_stack(([1,2,3],[4,5,6]))\n",
    "##array([[1, 4],\n",
    "##       [2, 5],\n",
    "##       [3, 6]])\n",
    "##>>> np.hstack(([1,2,3],[4,5,6]))\n",
    "##array([1, 2, 3, 4, 5, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(model, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeating the validation across different subsets of the data gives us an even better idea of the performance of the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagged decision trees like Random Forest and Extra Trees can be used to estimate the importance of features.\n",
    "\n",
    "Fits a number of randomized decision trees (a.k.a. extra-trees) on various sub-samples of the dataset and use averaging to improve the predictive accuracy and control over-fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(pca.transform(Xtrain), ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(10), model.feature_importances_)\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Relative Importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the first principal component always explains the most amount of variance in the input data, it doesn't mean that principal component is necessarily the most important in the ML classifier, as is evidenced here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support vector machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support vector machines (SVMs) are a particularly powerful and flexible class of supervised algorithms for both classification and regression. In this section, we will develop the intuition behind support vector machines and their use in classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A linear discriminative classifier would attempt to draw a straight line separating the two sets of data, and thereby create a model for classification. \n",
    "\n",
    "Below, we create two-dimensional data again using 2 principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca2  =  PCA(n_components =2)\n",
    "## fit to data\n",
    "pca2.fit(Xtrain)\n",
    "## apply the transformation\n",
    "images_pca2 = pca2.transform(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xfit = np.linspace(-30000, 30000)\n",
    "plt.scatter(images_pca2[:, 0], images_pca2[:, 1], c=ytrain, s=50, cmap='autumn')\n",
    "plt.plot([0.6], [2.1], 'x', color='red', markeredgewidth=2, markersize=10)\n",
    "for lab in range(len(ytrain)):\n",
    "    plt.text(images_pca2[lab, 0], images_pca2[lab, 1], str(ytrain[lab]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the clustering is there, but it is weak."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we will use a principal component analysis to extract 10 fundamental components to feed into our support vector machine classifier. We can do this most straightforwardly by packaging the preprocessor and the classifier into a single pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca  =  PCA(n_components =10)\n",
    "## fit to data\n",
    "pca.fit(Xtrain)\n",
    "## apply the transformation\n",
    "images_pca = pca.transform(Xtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 'pipeline' means to sequentially apply a list of transforms and a final estimator. Intermediate steps of the pipeline must be ‘transforms’, that is, they must implement fit and transform methods. The final estimator only needs to implement fit\n",
    "\n",
    "Below, we 'pipe' the output of the PCA analysis into the SVC classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pcamodel = PCA(svd_solver='randomized', n_components=10, whiten=True, random_state=42)\n",
    "svc = SVC(kernel='rbf', class_weight='balanced')\n",
    "model = make_pipeline(pcamodel, svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When evaluating different settings (“hyperparameters”) for estimators, such as the C setting that must be manually set for an SVM, there is still a risk of overfitting on the test set because the parameters can be tweaked until the estimator performs optimally. \n",
    "\n",
    "This way, knowledge about the test set can “leak” into the model and evaluation metrics no longer report on generalization performance. \n",
    "\n",
    "To solve this problem, yet another part of the dataset can be held out as a so-called “validation set”: training proceeds on the training set, after which evaluation is done on the validation set, and when the experiment seems to be successful, final evaluation can be done on the test set.\n",
    "\n",
    "However, by partitioning the available data into three sets, we drastically reduce the number of samples which can be used for learning the model, and the results can depend on a particular random choice for the pair of (train, validation) sets.\n",
    "\n",
    "A solution to this problem is a procedure called cross-validation (CV for short). A test set should still be held out for final evaluation, but the validation set is no longer needed when doing CV. In the basic approach, called k-fold CV, the training set is split into k smaller sets (other approaches are described below, but generally follow the same principles). The following procedure is followed for each of the k “folds”:\n",
    "\n",
    "* A model is trained using k-1 of the folds as training data;\n",
    "\n",
    "* the resulting model is validated on the remaining part of the data (i.e., it is used as a test set to compute a performance measure such as accuracy).\n",
    "\n",
    "\n",
    "The performance measure reported by k-fold cross-validation is then the average of the values computed in the loop. This approach can be computationally expensive, but does not waste too much data (as it is the case when fixing an arbitrary test set), which is a major advantage in problem such as inverse inference where the number of samples is very small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll do a limited grid search consistig of a few different likely values for two hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'svc__C': [1, 5, 10, 50],\n",
    "              'svc__gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01]}\n",
    "grid = GridSearchCV(model, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time grid.fit(images_pca, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_params_)\n",
    "grid.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = grid.best_estimator_\n",
    "yfit = model.predict(pca.transform(Xtest))           \n",
    "yfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot a few images and their predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4,4)\n",
    "fig.set_figheight(15)\n",
    "fig.set_figwidth(15)\n",
    "for i, axi in enumerate(ax.flat):\n",
    "    axi.imshow(Xtest[i].reshape(nx,ny,nz))\n",
    "    axi.set(xticks=[], yticks=[])\n",
    "    axi.set_ylabel(uniq_names[yfit[i]].split()[-1],\n",
    "                   color='black' if yfit[i] == ytest[i] else 'red')\n",
    "fig.suptitle('Predicted Names; Incorrect Labels in Red', size=14);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(ytest, ypred, target_names=uniq_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = confusion_matrix(ytest, yfit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(mat, classes=uniq_names,\n",
    "                      title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(mat, classes=uniq_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding airplanes with HOG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using HOG features, we can build up a simple image recognition algorithm with any Scikit-Learn estimator; here we will use a support vector machine.\n",
    "\n",
    "The steps are as follows:\n",
    "\n",
    "* Obtain a set of image thumbnails of airplanes to constitute \"positive\" training samples.\n",
    "* Obtain a set of image thumbnails of non-airplanes to constitute \"negative\" training samples.\n",
    "* Extract HOG features from these training samples.\n",
    "* Train a SVM classifier on these samples.\n",
    "* For an \"unknown\" image, pass a sliding window across the image, using the model to evaluate whether that window contains an airplane or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import feature, color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to build libraries of both positive (airplane) and negative (not airplane) examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [f for f in fs.ls(root+'/imrecog_data/NWPU-RESISC45/train/airplane') if f.endswith('.jpg')]\n",
    "\n",
    "positive_patches = []\n",
    "for name in names:\n",
    "    with fs.open(name, 'rb') as f:\n",
    "        positive_patches.append(color.rgb2gray(imread(f, 'jpg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(positive_patches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 350 airplane images to train on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.ls(root+'/imrecog_data/NWPU-RESISC45/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names1 = [f for f in fs.ls(root+'/imrecog_data/NWPU-RESISC45/test/baseball_diamond') if f.endswith('.jpg')]\n",
    "names2 = [f for f in fs.ls(root+'/imrecog_data/NWPU-RESISC45/test/airport') if f.endswith('.jpg')]\n",
    "names = names1 + names2\n",
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_patches = []\n",
    "for name in names:\n",
    "    with fs.open(name, 'rb') as f:\n",
    "        negative_patches.append(color.rgb2gray(imread(f, 'jpg')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at a few of them to get an idea of what they look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(5, 10)\n",
    "fig.set_figheight(15)\n",
    "fig.set_figwidth(15)\n",
    "for i, axi in enumerate(ax.flat):\n",
    "    axi.imshow(negative_patches[i], cmap='gray')\n",
    "    axi.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine and extract HOG features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have these positive samples and negative samples, we can combine them and compute HOG features. This step takes a little while, because the HOG features involve a nontrivial computation for each image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "X_train = np.array([feature.hog(im)\n",
    "                    for im in chain(positive_patches,\n",
    "                                    negative_patches)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx, ny = np.shape(X_train)\n",
    "y_train = np.zeros(nx)\n",
    "y_train[:len(positive_patches)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are left with 1050 training samples in 72,900 dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a support vector machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's use a simple Gaussian naive Bayes to get a quick baseline:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes classifiers are built on Bayesian classification methods. These rely on Bayes's theorem, which is an equation describing the relationship of conditional probabilities of statistical quantities. \n",
    "\n",
    "In Bayesian classification, we're interested in finding the probability of a label given some observed features, which we can write as $P(L~|~{\\rm features})$. Bayes's theorem tells us how to express this in terms of quantities we can compute more directly:\n",
    "\n",
    "$P(L~|~{\\rm features}) = \\frac{P({\\rm features}~|~L)P(L)}{P({\\rm features})}$\n",
    "\n",
    "If we are trying to decide between two labels—let's call them $L_1$ and $L_2$—then one way to make this decision is to compute the ratio of the posterior probabilities for each label:\n",
    "\n",
    "$$\n",
    "\\frac{P(L_1~|~{\\rm features})}{P(L_2~|~{\\rm features})} = \\frac{P({\\rm features}~|~L_1)}{P({\\rm features}~|~L_2)}\\frac{P(L_1)}{P(L_2)}\n",
    "$$\n",
    "\n",
    "All we need now is some model by which we can compute $P({\\rm features}~|~L_i)$ for each label. \n",
    "\n",
    "Why \"naive\" Bayes? If we make very naive assumptions about the generative model for each label, we can find a rough approximation of the generative model for each class, and then proceed with the Bayesian classification. \n",
    "\n",
    "In a Gaussian NB model, the assumption is that data from each label is drawn from a simple Gaussian distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "cross_val_score(GaussianNB(), X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is ~60%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For such a high-dimensional binary classification task, a Linear support vector machine is a good choice. We will use Scikit-Learn's LinearSVC, because in comparison to SVC it often has better scaling for large number of samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the support vector machine, with a grid search over a few choices of the C parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "grid = GridSearchCV(LinearSVC(), {'C': [0.125, 0.25, 0.5, 1.0]})\n",
    "grid.fit(X_train, y_train)\n",
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is 67%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = grid.best_estimator_\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding airplanes in new images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [f for f in fs.ls(root+'/imrecog_data/NWPU-RESISC45/test/airplane') if f.endswith('.jpg')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use one image and run a sliding window over it and evaluate each patch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import transform\n",
    "with fs.open(names[20], 'rb') as f:\n",
    "    test_image = imread(f, 'jpg')\n",
    "test_image = color.rgb2gray(test_image)\n",
    "test_image = transform.rescale(test_image,2)\n",
    "plt.imshow(test_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's create a window that iterates over patches of this image, and compute HOG features for each patch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(img, patch_size=positive_patches[0].shape,\n",
    "                   istep=2, jstep=2, scale=1.0):\n",
    "    Ni, Nj = (int(scale * s) for s in patch_size)\n",
    "    for i in range(0, img.shape[0] - Ni, istep):\n",
    "        for j in range(0, img.shape[1] - Ni, jstep):\n",
    "            patch = img[i:i + Ni, j:j + Nj]\n",
    "            if scale != 1:\n",
    "                patch = transform.resize(patch, patch_size)\n",
    "            yield (i, j), patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices, patches = zip(*sliding_window(test_image, istep=32, jstep=32))\n",
    "len(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(patches[10], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches_hog = np.array([feature.hog(patch) for patch in patches])\n",
    "patches_hog.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can take these HOG-featured patches and use our model to evaluate whether each patch contains an airplane:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = model.predict(patches_hog)\n",
    "labels.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that out of all the patches, we have found a few detections. Let's use the information we have about these patches to show where they lie on our test image, drawing them as rectangles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(test_image, cmap='gray')\n",
    "ax.axis('off')\n",
    "\n",
    "Ni, Nj = positive_patches[0].shape\n",
    "indices = np.array(indices)\n",
    "\n",
    "for i, j in indices[labels == 1]:\n",
    "    ax.add_patch(plt.Rectangle((j, i), Nj, Ni, edgecolor='red',\n",
    "                               alpha=0.3, lw=2, facecolor='none'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view this in a different way by creating a \"heatmap\" of identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = np.zeros(np.shape(test_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in indices[labels == 1]:\n",
    "    heatmap[i:i+Ni, j:j+Nj] = heatmap[i:i+Ni, j:j+Nj]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(10)\n",
    "ax.imshow(test_image, cmap='gray')\n",
    "plt.imshow(heatmap, alpha=0.5, vmax=20)\n",
    "plt.colorbar()\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it on some \"non-airplane\" imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [f for f in fs.ls(root+'/imrecog_data/NWPU-RESISC45/test/lake') if f.endswith('.jpg')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with fs.open(names[10], 'rb') as f:\n",
    "    test_image = imread(f, 'jpg')\n",
    "test_image = color.rgb2gray(test_image)\n",
    "test_image = transform.rescale(test_image,2)\n",
    "plt.imshow(test_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices, patches = zip(*sliding_window(test_image, istep=32, jstep=32))\n",
    "patches_hog = np.array([feature.hog(patch) for patch in patches])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = model.predict(patches_hog)\n",
    "labels.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = np.zeros(np.shape(test_image))\n",
    "\n",
    "Ni, Nj = positive_patches[0].shape\n",
    "indices = np.array(indices)\n",
    "\n",
    "for i, j in indices[labels == 1]:\n",
    "    heatmap[i:i+Ni, j:j+Nj] = heatmap[i:i+Ni, j:j+Nj]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(10)\n",
    "ax.imshow(test_image, cmap='gray')\n",
    "plt.imshow(heatmap, alpha=0.5, vmax=20)\n",
    "plt.colorbar()\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Tuning a random forest model\n",
    "2. Classifying plankton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Tuning a random forest model with respect to the number of features to consider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From ```RandomForestClassifier?```\n",
    "\n",
    "max_features : int, float, string or None, optional (default=\"auto\")\n",
    "    The number of features to consider when looking for the best split:\n",
    "\n",
    "    - If int, then consider `max_features` features at each split.\n",
    "    - If float, then `max_features` is a percentage and\n",
    "      `int(max_features * n_features)` features are considered at each\n",
    "      split.\n",
    "    - If \"auto\", then `max_features=sqrt(n_features)`.\n",
    "    - If \"sqrt\", then `max_features=sqrt(n_features)` (same as \"auto\").\n",
    "    - If \"log2\", then `max_features=log2(n_features)`.\n",
    "    - If None, then `max_features=n_features`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the sandbars dataset that we prepared earlier \n",
    "(training data = ```images_pca``` and ```ytrain```, testing data = ``pca.transform(Xtest)`` and ```ytest```)\n",
    "\n",
    "1. Create a list of max_features options\n",
    "2. In a loop ...\n",
    "    * cycle through each option\n",
    "    * ```fit``` the model to the training data\n",
    "    * ```predict``` labels for the testing data\n",
    "    * evaluate the accuracy of the prediction\n",
    "3. Plot the results - which choice yields most accuracy?   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Classifying plankton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a classifier to classify plankton images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a large data set, so be careful how much of it you use.\n",
    "\n",
    "For example, we could load up to the first 100 images from just the first 10 categories of plankton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cats = [f for f in fs.ls(root+'/imrecog_data/plankton/train')]\n",
    "train_names = []\n",
    "train_labels = []\n",
    "for cat in cats[:10]:\n",
    "    f = [f for f in fs.ls(cat) if f.endswith('.jpg')][:100]\n",
    "    train_names.extend(f)\n",
    "    train_labels.extend([cat.split(os.sep)[-1] for i in range(len(f))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_labels))\n",
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing, we could sample the last 10 images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_names = []\n",
    "test_labels = []\n",
    "for cat in cats[:10]:\n",
    "    f = [f for f in fs.ls(cat) if f.endswith('.jpg')][-10:]\n",
    "    test_names.extend(f)\n",
    "    test_labels.extend([cat.split(os.sep)[-1] for i in range(len(f))])\n",
    "print(len(test_labels))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now come up with a classifier!\n",
    "\n",
    "(note: the images are different sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
